
import numpy as np

from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Union

from pykokkos.runtime import runtime_singleton
import pykokkos.kokkos_manager as km
from pykokkos.core.type_inference import UpdatedTypes, UpdatedDecorator, HandledArgs, get_annotations, get_views_decorator, handle_args

from .execution_policy import ExecutionPolicy
from .execution_space import ExecutionSpace
from .views import array

workunit_cache: Dict[int, Callable] = {}


def check_policy(policy: Any) -> None:
    """
    Check if an argument is a valid execution policy and raise an
    exception otherwise

    :param policy: the potential policy to be checked
    """

    if not isinstance(policy, (int, ExecutionPolicy)):
        raise TypeError(f"ERROR: {policy} is not a valid execution policy")


def check_workunit(workunit: Any) -> None:
    """
    Check if an argument is a valid workunit and raise an exception
    otherwise

    :param workunit: the potential workunit to be checked
    """

    if not callable(workunit):
        raise TypeError(f"ERROR: {workunit} is not a valid workunit")


def parallel_for(*args, **kwargs) -> None:
    """
    Run a parallel for loop

    :param *args: 
        :param name: (optional) name of the kernel
        :param policy: the execution policy, either a RangePolicy,
            TeamPolicy, TeamThreadRange, ThreadVectorRange, or an
            integer representing the number of threads
        :param workunit: the workunit to be run in parallel
        :param view: (optional) the view being initialized

    :param **kwargs: the keyword arguments passed to a standalone
        workunit
    """

    handled_args: HandledArgs = handle_args(True, args)

    for el in kwargs:
        if isinstance(kwargs[el], np.ndarray):
            kwargs[el] = array(kwargs[el])

    updated_types: UpdatedTypes = get_annotations("parallel_for", handled_args, args, passed_kwargs=kwargs)
    updated_decorator: UpdatedDecorator = get_views_decorator(handled_args, passed_kwargs=kwargs)

    func, args = runtime_singleton.runtime.run_workunit(
        handled_args.name,
        handled_args.policy,
        handled_args.workunit,
        "for",
        updated_decorator,
        updated_types,
        **kwargs)

    # workunit_cache[cache_key] = (func, args)
    func(**args)

def reduce_body(operation: str, *args, **kwargs) -> Union[float, int]:
    """
    Internal method to avoid duplication parallel_reduce and
    parallel_scan bodies

    :param operation: the name of the operation, "reduce" or "scan"
    """

    args_to_hash: List = []
    args_not_to_hash: Dict = {}
    for k, v in kwargs.items():
        if not isinstance(v, int):
            args_to_hash.append(v)
        else:
            args_not_to_hash[k] = v

    for a in args:
        if callable(a):
            args_to_hash.append(a.__name__)
            break

    args_to_hash.append(operation)

    to_hash = frozenset(args_to_hash)
    cache_key: int = hash(to_hash)

    if cache_key in workunit_cache:
        func, args = workunit_cache[cache_key]
        args.update(args_not_to_hash)
        return func(**args)

    handled_args: HandledArgs = handle_args(True, args)

    #* Inferring missing data types
    updated_types: UpdatedTypes = get_annotations(f"parallel_{operation}", handled_args, args, passed_kwargs=kwargs)
    updated_decorator: UpdatedDecorator = get_views_decorator(handled_args, passed_kwargs=kwargs)

    func, args = runtime_singleton.runtime.run_workunit(
        handled_args.name,
        handled_args.policy,
        handled_args.workunit,
        operation,
        updated_decorator,
        updated_types,
        **kwargs)

    workunit_cache[cache_key] = (func, args)
    return func(**args)

def parallel_reduce(*args, **kwargs) -> Union[float, int]:
    """
    Run a parallel reduction

    :param *args: 
        :param name: (optional) name of the kernel
        :param policy: the execution policy, either a RangePolicy,
            TeamPolicy, TeamThreadRange, ThreadVectorRange, or an
            integer representing the number of threads
        :param workunit: the workunit to be run in parallel
        :param initial_value: (optional) the initial value of the
            reduction

    :param **kwargs: the keyword arguments passed to a standalone
        workunit
    """

    return reduce_body("reduce", *args, **kwargs)


def parallel_scan(*args, **kwargs) -> Union[float, int]:
    """
    Run a parallel reduction

    :param *args: 
        :param name: (optional) name of the kernel
        :param policy: the execution policy, either a RangePolicy,
            TeamPolicy, TeamThreadRange, ThreadVectorRange, or an
            integer representing the number of threads
        :param workunit: the workunit to be run in parallel
        :param initial_value: (optional) the initial value of the
            reduction

    :param **kwargs: the keyword arguments passed to a standalone
        workunit
    """

    return reduce_body("scan", *args, **kwargs)


def execute(space: ExecutionSpace, workload: object) -> None:
    if space is ExecutionSpace.Default:
        runtime_singleton.runtime.run_workload(km.get_default_space(), workload)
    else:
        runtime_singleton.runtime.run_workload(space, workload)

